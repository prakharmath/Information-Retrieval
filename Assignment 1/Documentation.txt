Documentation for Assignment 1 for Information Retrieval Course(Submitted by Prakhar Bindal 17CS10036)
Task 2
The file named ASSIGNMENT1_17CS10036_2.py contains the code for the second part of the assignment. The code takes the input from a folder named "data" which is present in the same directory as the code. The Code parses all the HTML files which are present in the data folder according to the conditions given in the assignment and makes a nested dictionary containing all the data of it. All the nested Dictionaries are then dumped into a folder named ECTNestedDict which is also created by the code. Afterwards the whole text corpus is then dumped into a folder named ECTText which will contain the text data of all the HTML files. 
The code can simply be run by typing python3 ASSIGNMENT1_17CS10036_2.py on your terminal.
The time taken by the code to parse all the files varies greatly from system to system and depends on the processing speed of your processor as well as number tasks that you are trying to execute simultaneously.
On My System(Intel Core i7 8th Generation 3.8 MHz Clock speed) it takes approximately 2 minutes to Parse all the files. 
NOTE-As it wasnt really clear from Teams as well as from the assignment for making the text corpus i have provided two options 1) By Dumping the whole data extracted using beautifulsoup from the HTML files into our text corpus 
2) By extracting the data from the nested dictionary which we just made.
1) option will make quite more sense to do because we will be able to get whole data of the html pages and wont be  missing any information as we cant really make a perfect dictionary.Moreover when we made a dictionary we have lost the original ordering of the text as they were spoken during the conversation . Hence it will make much more sense to go ahead with part 1.
By default i have provided the code with extracting data directly from html files.But i have also given the code for dictionary one which is commented out. To build the text corpus using dictionary please comment out line 135(print(soup.get_text().lower())) and uncomment lines from 136-151(print(date) to print(z.lower())).
Task 3
The file named ASSIGNMENT1_17CS10036_3.py contains the code for the third part of the assignment. The code takes input from the folder named ECTText which contains our text corpus , Lemmatizes the data,Removes Punctuations and other symbols,Builds the inverted indexed dictionary for wild card search and dumps the built inverted indexed dictionary into a json file which will be used for answering wild card queries in 4th part of the assignment.
In the Lemmatization part using the NLTK library of python initially i was not providing any tag argument to the lemmatizer. as a result lemmatization was not being done properly(Study and Studying were different tokens even after lemmatizing). So i have applied pos tag while lemmatization. But the drawback of that approach is it is taking more time than the lemmatization without using pos tag. So i have by default given the code of lemmatization using proper pos tags but have also given the code without using pos tag which is commented out.
On My system(Intel Core i7 8th Generation 3.8 MHz Clock speed) it takes approximately 25-27 minutes to lemmatize full data and dump the inverted indexed dictionary into json. Without using pos tag lemmatization takes approximately 6-7 minutes to lemmtaize full data.
If you want to run the lemmatization code without using pos tag please comment out lines from (58-75) and uncomment lines from(45-57). This code can simply be run by using python3 ASSIGNMENT1_17CS10036_3.py.
Task 4
The file named ASSIGNMENT1_17CS10036_4.py contains the code for the fourth part of the assignment. The code takes as input file name which contains the wild card queries as a command line argument. It basically uses binary search to find the matchings and then prints them in the required format. The output data is dumped into a file named RESULTS1_17CS10036.txt which is created in the same directory as our code.
On My system(Intel Core i7 8th Generation 3.8 MHz Clock speed) it takes approximately 5 seconds to load the inverted indexed dictionary JSON which was created in the previous task of the assignment.After that a single query isnt taking more than a second to execute.